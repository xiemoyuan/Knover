# task settings
model=UnifiedTransformer
task=DialogGeneration

vocab_path="./package/dialog_zh/ccf_baseline/vocab.txt"
spm_model_file="./package/dialog_zh/ccf_baseline/sp.model"
train_file="./data/train.shuffle.txt"
valid_file="./data/valid.txt"
data_format="numerical"
file_format="file"
config_path="./package/dialog_zh/ccf_baseline/12L.json"

# training settings
init_params="./dict/12L.pretrain"
in_tokens="true"
batch_size=8192
lr=1e-5
warmup_steps=4000
weight_decay=0.01
num_epochs=10

train_args="--max_src_len 384 --max_tgt_len 128 --max_seq_len 512"

log_steps=500
validation_steps=8000
save_steps=8000

log_dir="./log"
save_path="./output"
