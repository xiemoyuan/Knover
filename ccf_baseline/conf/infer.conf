# task settings
model=UnifiedTransformer
task=DialogGeneration

vocab_path="./package/dialog_zh/ccf_baseline/vocab.txt"
spm_model_file="./package/dialog_zh/ccf_baseline/sp.model"
infer_file="data/test.txt"
data_format="numerical"
file_format="file"
config_path="./package/dialog_zh/ccf_baseline/12L.json"

# training settings
init_params="./dict/step_80000"
in_tokens="false"
batch_size=4

output_name="response"

# top-k sampling(k = 10) and rerank by length-average ppl(20 samples)
infer_args="--do_generation true --decoding_strategy topk_sampling --num_samples 20 --topk 5 --is_cn true"
# top-p sampling(p = 0.9) and rerank by length-average ppl(20 samples)
# infer_args="--do_generation true --decoding_strategy topp_sampling --num_samples 20 --topp 0.9"
# beam_search(beam size = 10)
# infer_args="--do_generation true --decoding_strategy beam_search --beam_size 1"

log_dir="./log"
save_path="./output"
