# Knover
Knover is a toolkit for knowledge grounded dialogue generation based on PaddlePaddle. Knover allows researchers and developers to carry out efficient training/inference of large-scale dialogue generation models. 

### What's New:

- July 2020: We are opening [PLATO-2](plato-2/README.md), a large-scale generative model with latent space for open-domain dialogue systems.


## Basic usage:

### Training
Training model with a training configuration file in local. You can specify GPU by `export CUDA_VISIBLE_DEVICES=XXX` in `./scripts/local/train.sh`.

``` bash
./scripts/local/train.sh ${TRAIN_CONF}
```

Training model with a training configuration file in paddlecloud (k8s cluster).

``` bash
./scripts/paddlecloud/k8s_submit.sh ${TRAIN_CONF}
```

An example of training configuration files is `./package/dialog_en/24L_train.conf`. It contains four sections: `job`, `afs/hdfs`, `task` and `training`.

#### job
This section is only used in a paddlecloud job.

This section defines:

`task_name`: task name

`job_script`: the main script of this task; use `./scripts/distributed/train.sh` for training task.

`nodes`: the number of training nodes

`cards`: the number of cards use in each node

`fs_name && fs_ugi`: the used hdfs/afs cluster (`fs_name` and `fs_ugi`)

`output_path`: the output path in cluster (`output_path`)

and other settings for a paddlecloud job.

#### afs/hdfs
This section is only used in a paddlecloud job.

This section defines the files/dirs which are need to mount/download from afs/hdfs cluster.

#### task
This section defines:

`model`: the used model class

`task`: task name

`vocab_path`: vocabulary

tokenizer related: `spm_model_file` for SentencePieces Tokenizer, and so on.

dataset files related: `train_file`, `valid_file`, `data_format` and `file_format`.

`config_path`: model configuration file.

Choices of `data_format`:

`raw` (untokenized data tsv file, example: `./data/train.tsv`), `tokenized` (tokenized data tsv, example: `./data/train_tokenized.tsv` which is generated by `./tools/pre_tokenized.sh`) and `numerical` (each line contains numerical data: `token_ids`, `type_ids` and `pos_ids`, `role_ids` for optional, example: `./data/train.numerical.tsv` which is generated by `./tools/pre_numericalize.sh`).

It also supports the file with `.gz` suffix which is compressed by `gzip` command now.

Choices of `file_format`: `file` (a file only) and `filelist` (contains multiple files, each file in a line, example: `./data/train_filelist`).

#### training
This section defines training related settings:

`init_params`: initialized parameters.

`batch_size`, `lr`, `num_epochs` and so on.

`log_dir`: the output path of training logs, include the log file (`${log_dir}/workerlog.${DEV_ID}`) of each GPU trainer. If `log_dir=""`, then the output of all GPU trainers will output to standard output.

`save_path`: the output path of saved parameters.

You can define other arguments in training script, such as:

```
train_args="--max_src_len 384 --max_seq_len 512"
```

### Inference
Run inference in local.

```bash
./scripts/local/infer.sh ${INFER_CONF}
```

Run inference in paddlecloud (k8s cluster).

```bash
./scripts/paddlecloud/k8s_submit ${INFER_CONF}
```

An example of inference configuration files is `./package/dialog_en/24L_infer.conf`. It also contains four sections: `job`, `afs/hdfs`, `task` and `inference`.

These sections defines the same settings as traing job except:

`job_script` (`job` section): the main script of this task; use `./scripts/distributed/infer.sh` for inference task.

You also can define other arguments in inference script, such as:

```
infer_args="--do_generation true"
```

top-k sampling and rerank:

```
infer_args="--do_generation true --decoding_strategy topk_sampling --num_samples 20 --topk 10 --length_average true"
```

top-p sampling and rerank:

```
infer_args="--do_generation true --decoding_strategy topp_sampling --num_samples 20 --topp 0.9 --length_average true"
```

beam search:

```
infer_args="--do_generation true --decoding_strategy beam_search --beam_size 10 --length_average true"
```
